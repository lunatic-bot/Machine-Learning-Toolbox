{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbA740Dfx_aV"
      },
      "source": [
        "## FLAML: A Fast and Lightweight AutoML Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhC_ulqGvYSq",
        "outputId": "7b48070b-31ec-4e52-e3f3-3441caf1c236"
      },
      "source": [
        "!pip install flaml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flaml\n",
            "  Downloading FLAML-0.6.5-py3-none-any.whl (156 kB)\n",
            "\u001b[K     |████████████████████████████████| 156 kB 2.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: NumPy>=1.16.2 in /usr/local/lib/python3.7/dist-packages (from flaml) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from flaml) (1.4.1)\n",
            "Collecting lightgbm>=2.3.1\n",
            "  Downloading lightgbm-3.2.1-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 11.6 MB/s \n",
            "\u001b[?25hCollecting catboost>=0.23\n",
            "  Downloading catboost-1.0.0-cp37-none-manylinux1_x86_64.whl (76.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 76.4 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting scikit-learn>=0.24\n",
            "  Downloading scikit_learn-1.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.1 MB 12.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: xgboost<=1.3.3,>=0.90 in /usr/local/lib/python3.7/dist-packages (from flaml) (0.90)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost>=0.23->flaml) (0.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost>=0.23->flaml) (1.15.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost>=0.23->flaml) (1.1.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost>=0.23->flaml) (3.2.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost>=0.23->flaml) (4.4.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm>=2.3.1->flaml) (0.37.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost>=0.23->flaml) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost>=0.23->flaml) (2018.9)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-2.2.0-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->flaml) (1.0.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost>=0.23->flaml) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost>=0.23->flaml) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost>=0.23->flaml) (2.4.7)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost>=0.23->flaml) (1.3.3)\n",
            "Installing collected packages: threadpoolctl, scikit-learn, lightgbm, catboost, flaml\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "Successfully installed catboost-1.0.0 flaml-0.6.5 lightgbm-3.2.1 scikit-learn-1.0 threadpoolctl-2.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00xUXNvfwyXV"
      },
      "source": [
        "# Classification Problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDEkaxcDvJuB",
        "outputId": "a92f1e8e-7f19-4389-bc99-f44c3d81ce82"
      },
      "source": [
        "from flaml import AutoML\n",
        "from sklearn.datasets import load_iris\n",
        "# Initialize an AutoML instance\n",
        "automl = AutoML()\n",
        "# Specify automl goal and constraint\n",
        "automl_settings = {\n",
        "    \"time_budget\": 10,  # in seconds\n",
        "    \"metric\": 'accuracy',\n",
        "    \"task\": 'classification',\n",
        "    \"log_file_name\": \"iris.log\",\n",
        "}\n",
        "X_train, y_train = load_iris(return_X_y=True)\n",
        "# Train with labeled input data\n",
        "automl.fit(X_train=X_train, y_train=y_train,\n",
        "           **automl_settings)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[flaml.automl: 10-01 12:29:07] {1432} INFO - Evaluation method: cv\n",
            "[flaml.automl: 10-01 12:29:07] {1478} INFO - Minimizing error metric: 1-accuracy\n",
            "[flaml.automl: 10-01 12:29:07] {1515} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'lrl1']\n",
            "[flaml.automl: 10-01 12:29:07] {1748} INFO - iteration 0, current learner lgbm\n",
            "[flaml.automl: 10-01 12:29:07] {1866} INFO - Estimated sufficient time budget=249s. Estimated necessary time budget=5s.\n",
            "[flaml.automl: 10-01 12:29:07] {1944} INFO -  at 0.0s,\testimator lgbm's best error=0.0733,\tbest estimator lgbm's best error=0.0733\n",
            "[flaml.automl: 10-01 12:29:07] {1748} INFO - iteration 1, current learner lgbm\n",
            "[flaml.automl: 10-01 12:29:07] {1944} INFO -  at 0.1s,\testimator lgbm's best error=0.0733,\tbest estimator lgbm's best error=0.0733\n",
            "[flaml.automl: 10-01 12:29:07] {1748} INFO - iteration 2, current learner lgbm\n",
            "[flaml.automl: 10-01 12:29:07] {1944} INFO -  at 0.1s,\testimator lgbm's best error=0.0533,\tbest estimator lgbm's best error=0.0533\n",
            "[flaml.automl: 10-01 12:29:07] {1748} INFO - iteration 3, current learner xgboost\n",
            "[flaml.automl: 10-01 12:29:07] {1944} INFO -  at 0.1s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0533\n",
            "[flaml.automl: 10-01 12:29:07] {1748} INFO - iteration 4, current learner lgbm\n",
            "[flaml.automl: 10-01 12:29:07] {1944} INFO -  at 0.2s,\testimator lgbm's best error=0.0533,\tbest estimator lgbm's best error=0.0533\n",
            "[flaml.automl: 10-01 12:29:07] {1748} INFO - iteration 5, current learner lgbm\n",
            "[flaml.automl: 10-01 12:29:07] {1944} INFO -  at 0.2s,\testimator lgbm's best error=0.0533,\tbest estimator lgbm's best error=0.0533\n",
            "[flaml.automl: 10-01 12:29:07] {1748} INFO - iteration 6, current learner lgbm\n",
            "[flaml.automl: 10-01 12:29:07] {1944} INFO -  at 0.2s,\testimator lgbm's best error=0.0467,\tbest estimator lgbm's best error=0.0467\n",
            "[flaml.automl: 10-01 12:29:07] {1748} INFO - iteration 7, current learner lgbm\n",
            "[flaml.automl: 10-01 12:29:07] {1944} INFO -  at 0.3s,\testimator lgbm's best error=0.0467,\tbest estimator lgbm's best error=0.0467\n",
            "[flaml.automl: 10-01 12:29:07] {1748} INFO - iteration 8, current learner lgbm\n",
            "[flaml.automl: 10-01 12:29:07] {1944} INFO -  at 0.3s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl: 10-01 12:29:07] {1748} INFO - iteration 9, current learner lgbm\n",
            "[flaml.automl: 10-01 12:29:07] {1944} INFO -  at 0.3s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl: 10-01 12:29:07] {1748} INFO - iteration 10, current learner xgboost\n",
            "[flaml.automl: 10-01 12:29:08] {1944} INFO -  at 0.4s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl: 10-01 12:29:08] {1748} INFO - iteration 11, current learner xgboost\n",
            "[flaml.automl: 10-01 12:29:08] {1944} INFO -  at 0.4s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl: 10-01 12:29:08] {1748} INFO - iteration 12, current learner extra_tree\n",
            "[flaml.automl: 10-01 12:29:09] {1944} INFO -  at 1.6s,\testimator extra_tree's best error=0.0667,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl: 10-01 12:29:09] {1748} INFO - iteration 13, current learner rf\n",
            "[flaml.automl: 10-01 12:29:10] {1944} INFO -  at 2.7s,\testimator rf's best error=0.0733,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl: 10-01 12:29:10] {1748} INFO - iteration 14, current learner lgbm\n",
            "[flaml.automl: 10-01 12:29:10] {1944} INFO -  at 2.7s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl: 10-01 12:29:10] {1748} INFO - iteration 15, current learner xgboost\n",
            "[flaml.automl: 10-01 12:29:10] {1944} INFO -  at 2.8s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl: 10-01 12:29:10] {1748} INFO - iteration 16, current learner lgbm\n",
            "[flaml.automl: 10-01 12:29:10] {1944} INFO -  at 2.8s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl: 10-01 12:29:10] {1748} INFO - iteration 17, current learner xgboost\n",
            "[flaml.automl: 10-01 12:29:10] {1944} INFO -  at 2.8s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl: 10-01 12:29:10] {1748} INFO - iteration 18, current learner lgbm\n",
            "[flaml.automl: 10-01 12:29:10] {1944} INFO -  at 2.9s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl: 10-01 12:29:10] {1748} INFO - iteration 19, current learner xgboost\n",
            "[flaml.automl: 10-01 12:29:10] {1944} INFO -  at 2.9s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl: 10-01 12:29:10] {1748} INFO - iteration 20, current learner lgbm\n",
            "[flaml.automl: 10-01 12:29:10] {1944} INFO -  at 2.9s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl: 10-01 12:29:10] {1748} INFO - iteration 21, current learner xgboost\n",
            "[flaml.automl: 10-01 12:29:10] {1944} INFO -  at 3.0s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl: 10-01 12:29:10] {1748} INFO - iteration 22, current learner lgbm\n",
            "[flaml.automl: 10-01 12:29:10] {1944} INFO -  at 3.0s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl: 10-01 12:29:10] {1748} INFO - iteration 23, current learner lgbm\n",
            "[flaml.automl: 10-01 12:29:10] {1944} INFO -  at 3.0s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl: 10-01 12:29:10] {1748} INFO - iteration 24, current learner xgboost\n",
            "[flaml.automl: 10-01 12:29:10] {1944} INFO -  at 3.1s,\testimator xgboost's best error=0.0467,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl: 10-01 12:29:10] {1748} INFO - iteration 25, current learner extra_tree\n",
            "[flaml.automl: 10-01 12:29:11] {1944} INFO -  at 4.2s,\testimator extra_tree's best error=0.0333,\tbest estimator extra_tree's best error=0.0333\n",
            "[flaml.automl: 10-01 12:29:11] {1748} INFO - iteration 26, current learner catboost\n",
            "[flaml.automl: 10-01 12:29:12] {1944} INFO -  at 4.8s,\testimator catboost's best error=0.0467,\tbest estimator extra_tree's best error=0.0333\n",
            "[flaml.automl: 10-01 12:29:12] {1748} INFO - iteration 27, current learner rf\n",
            "[flaml.automl: 10-01 12:29:13] {1944} INFO -  at 6.0s,\testimator rf's best error=0.0600,\tbest estimator extra_tree's best error=0.0333\n",
            "[flaml.automl: 10-01 12:29:13] {1748} INFO - iteration 28, current learner xgboost\n",
            "[flaml.automl: 10-01 12:29:13] {1944} INFO -  at 6.0s,\testimator xgboost's best error=0.0467,\tbest estimator extra_tree's best error=0.0333\n",
            "[flaml.automl: 10-01 12:29:13] {1748} INFO - iteration 29, current learner extra_tree\n",
            "[flaml.automl: 10-01 12:29:14] {1944} INFO -  at 7.1s,\testimator extra_tree's best error=0.0333,\tbest estimator extra_tree's best error=0.0333\n",
            "[flaml.automl: 10-01 12:29:14] {1748} INFO - iteration 30, current learner extra_tree\n",
            "[flaml.automl: 10-01 12:29:16] {1944} INFO -  at 8.4s,\testimator extra_tree's best error=0.0333,\tbest estimator extra_tree's best error=0.0333\n",
            "[flaml.automl: 10-01 12:29:16] {1748} INFO - iteration 31, current learner lgbm\n",
            "[flaml.automl: 10-01 12:29:16] {1944} INFO -  at 8.4s,\testimator lgbm's best error=0.0400,\tbest estimator extra_tree's best error=0.0333\n",
            "[flaml.automl: 10-01 12:29:16] {1748} INFO - iteration 32, current learner lgbm\n",
            "[flaml.automl: 10-01 12:29:16] {1944} INFO -  at 8.5s,\testimator lgbm's best error=0.0400,\tbest estimator extra_tree's best error=0.0333\n",
            "[flaml.automl: 10-01 12:29:16] {1748} INFO - iteration 33, current learner lgbm\n",
            "[flaml.automl: 10-01 12:29:16] {1944} INFO -  at 8.5s,\testimator lgbm's best error=0.0400,\tbest estimator extra_tree's best error=0.0333\n",
            "[flaml.automl: 10-01 12:29:16] {1748} INFO - iteration 34, current learner xgboost\n",
            "[flaml.automl: 10-01 12:29:16] {1944} INFO -  at 8.5s,\testimator xgboost's best error=0.0467,\tbest estimator extra_tree's best error=0.0333\n",
            "[flaml.automl: 10-01 12:29:16] {1748} INFO - iteration 35, current learner lgbm\n",
            "[flaml.automl: 10-01 12:29:16] {1944} INFO -  at 8.5s,\testimator lgbm's best error=0.0400,\tbest estimator extra_tree's best error=0.0333\n",
            "[flaml.automl: 10-01 12:29:16] {1748} INFO - iteration 36, current learner catboost\n",
            "[flaml.automl: 10-01 12:29:16] {1944} INFO -  at 8.9s,\testimator catboost's best error=0.0467,\tbest estimator extra_tree's best error=0.0333\n",
            "[flaml.automl: 10-01 12:29:16] {1748} INFO - iteration 37, current learner extra_tree\n",
            "[flaml.automl: 10-01 12:29:17] {1944} INFO -  at 10.0s,\testimator extra_tree's best error=0.0333,\tbest estimator extra_tree's best error=0.0333\n",
            "[flaml.automl: 10-01 12:29:17] {2043} INFO - selected model: ExtraTreesClassifier(max_features=0.9692029582222275, max_leaf_nodes=6,\n",
            "                     n_estimators=4, n_jobs=-1)\n",
            "[flaml.automl: 10-01 12:29:17] {2106} INFO - retrain extra_tree for 0.2s\n",
            "[flaml.automl: 10-01 12:29:17] {2110} INFO - retrained model: ExtraTreesClassifier(max_features=0.9692029582222275, max_leaf_nodes=6,\n",
            "                     n_estimators=4, n_jobs=-1)\n",
            "[flaml.automl: 10-01 12:29:17] {1539} INFO - fit succeeded\n",
            "[flaml.automl: 10-01 12:29:17] {1541} INFO - Time taken to find the best model: 4.214092969894409\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-3p9iLJvWwz",
        "outputId": "db2106b2-0404-4ab2-d9fa-e68e72f29922"
      },
      "source": [
        "# Predict\n",
        "print(automl.predict_proba(X_train))\n",
        "# Export the best model\n",
        "print(automl.model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [0.         0.87678571 0.12321429]\n",
            " [0.         0.79783835 0.20216165]\n",
            " [0.         0.46869756 0.53130244]\n",
            " [0.         0.97916667 0.02083333]\n",
            " [0.         0.79783835 0.20216165]\n",
            " [0.         0.9125     0.0875    ]\n",
            " [0.         0.79783835 0.20216165]\n",
            " [0.         0.97916667 0.02083333]\n",
            " [0.         0.9125     0.0875    ]\n",
            " [0.         0.94345238 0.05654762]\n",
            " [0.         0.97916667 0.02083333]\n",
            " [0.         0.79783835 0.20216165]\n",
            " [0.         0.9375     0.0625    ]\n",
            " [0.         0.87678571 0.12321429]\n",
            " [0.         0.9375     0.0625    ]\n",
            " [0.         0.87678571 0.12321429]\n",
            " [0.         0.79783835 0.20216165]\n",
            " [0.         0.9375     0.0625    ]\n",
            " [0.         0.79783835 0.20216165]\n",
            " [0.         0.9375     0.0625    ]\n",
            " [0.         0.79783835 0.20216165]\n",
            " [0.         0.9375     0.0625    ]\n",
            " [0.         0.46869756 0.53130244]\n",
            " [0.         0.9125     0.0875    ]\n",
            " [0.         0.9125     0.0875    ]\n",
            " [0.         0.87678571 0.12321429]\n",
            " [0.         0.87678571 0.12321429]\n",
            " [0.         0.36014493 0.63985507]\n",
            " [0.         0.79783835 0.20216165]\n",
            " [0.         0.9375     0.0625    ]\n",
            " [0.         0.97916667 0.02083333]\n",
            " [0.         0.97916667 0.02083333]\n",
            " [0.         0.9375     0.0625    ]\n",
            " [0.         0.30359731 0.69640269]\n",
            " [0.         0.83950501 0.16049499]\n",
            " [0.         0.79783835 0.20216165]\n",
            " [0.         0.79783835 0.20216165]\n",
            " [0.         0.9125     0.0875    ]\n",
            " [0.         0.9375     0.0625    ]\n",
            " [0.         0.97916667 0.02083333]\n",
            " [0.         0.95416667 0.04583333]\n",
            " [0.         0.87678571 0.12321429]\n",
            " [0.         0.9375     0.0625    ]\n",
            " [0.         0.97916667 0.02083333]\n",
            " [0.         0.9125     0.0875    ]\n",
            " [0.         0.9125     0.0875    ]\n",
            " [0.         0.9125     0.0875    ]\n",
            " [0.         0.9125     0.0875    ]\n",
            " [0.         0.97916667 0.02083333]\n",
            " [0.         0.9375     0.0625    ]\n",
            " [0.         0.00595238 0.99404762]\n",
            " [0.         0.30359731 0.69640269]\n",
            " [0.         0.00595238 0.99404762]\n",
            " [0.         0.04943064 0.95056936]\n",
            " [0.         0.00595238 0.99404762]\n",
            " [0.         0.00595238 0.99404762]\n",
            " [0.         0.83950501 0.16049499]\n",
            " [0.         0.00595238 0.99404762]\n",
            " [0.         0.04943064 0.95056936]\n",
            " [0.         0.00595238 0.99404762]\n",
            " [0.         0.30359731 0.69640269]\n",
            " [0.         0.04943064 0.95056936]\n",
            " [0.         0.00595238 0.99404762]\n",
            " [0.         0.36014493 0.63985507]\n",
            " [0.         0.00595238 0.99404762]\n",
            " [0.         0.00595238 0.99404762]\n",
            " [0.         0.04943064 0.95056936]\n",
            " [0.         0.00595238 0.99404762]\n",
            " [0.         0.00595238 0.99404762]\n",
            " [0.         0.36014493 0.63985507]\n",
            " [0.         0.00595238 0.99404762]\n",
            " [0.         0.46869756 0.53130244]\n",
            " [0.         0.00595238 0.99404762]\n",
            " [0.         0.46869756 0.53130244]\n",
            " [0.         0.00595238 0.99404762]\n",
            " [0.         0.00595238 0.99404762]\n",
            " [0.         0.79783835 0.20216165]\n",
            " [0.         0.46869756 0.53130244]\n",
            " [0.         0.00595238 0.99404762]\n",
            " [0.         0.04943064 0.95056936]\n",
            " [0.         0.00595238 0.99404762]\n",
            " [0.         0.00595238 0.99404762]\n",
            " [0.         0.00595238 0.99404762]\n",
            " [0.         0.30359731 0.69640269]\n",
            " [0.         0.04943064 0.95056936]\n",
            " [0.         0.00595238 0.99404762]\n",
            " [0.         0.00595238 0.99404762]\n",
            " [0.         0.04943064 0.95056936]\n",
            " [0.         0.79783835 0.20216165]\n",
            " [0.         0.00595238 0.99404762]\n",
            " [0.         0.00595238 0.99404762]\n",
            " [0.         0.00595238 0.99404762]\n",
            " [0.         0.30359731 0.69640269]\n",
            " [0.         0.00595238 0.99404762]\n",
            " [0.         0.00595238 0.99404762]\n",
            " [0.         0.00595238 0.99404762]\n",
            " [0.         0.36014493 0.63985507]\n",
            " [0.         0.04943064 0.95056936]\n",
            " [0.         0.00595238 0.99404762]\n",
            " [0.         0.30359731 0.69640269]]\n",
            "<flaml.model.ExtraTreeEstimator object at 0x7f0a9ea30550>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXE4twtlwk1x"
      },
      "source": [
        "# Regression Problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENQ6nHCMwEFi",
        "outputId": "b4c4bdff-34d7-4e5d-ac9e-82ddbeae3f04"
      },
      "source": [
        "## Regression Problem\n",
        "from flaml import AutoML\n",
        "from sklearn.datasets import load_boston\n",
        "# Initialize an AutoML instance\n",
        "automl = AutoML()\n",
        "# Specify automl goal and constraint\n",
        "automl_settings = {\n",
        "    \"time_budget\": 10,  # in seconds\n",
        "    \"metric\": 'r2',\n",
        "    \"task\": 'regression',\n",
        "    \"log_file_name\": \"boston.log\",\n",
        "}\n",
        "X_train, y_train = load_boston(return_X_y=True)\n",
        "# Train with labeled input data\n",
        "automl.fit(X_train=X_train, y_train=y_train,\n",
        "           **automl_settings)\n",
        "# Predict\n",
        "print(automl.predict(X_train))\n",
        "# Export the best model\n",
        "print(automl.model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this case special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows:\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and:\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "    \n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "[flaml.automl: 10-01 12:31:13] {1432} INFO - Evaluation method: cv\n",
            "[flaml.automl: 10-01 12:31:13] {1478} INFO - Minimizing error metric: 1-r2\n",
            "[flaml.automl: 10-01 12:31:14] {1515} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree']\n",
            "[flaml.automl: 10-01 12:31:14] {1748} INFO - iteration 0, current learner lgbm\n",
            "[flaml.automl: 10-01 12:31:14] {1866} INFO - Estimated sufficient time budget=269s. Estimated necessary time budget=1s.\n",
            "[flaml.automl: 10-01 12:31:14] {1944} INFO -  at 0.0s,\testimator lgbm's best error=0.6257,\tbest estimator lgbm's best error=0.6257\n",
            "[flaml.automl: 10-01 12:31:14] {1748} INFO - iteration 1, current learner lgbm\n",
            "[flaml.automl: 10-01 12:31:14] {1944} INFO -  at 0.1s,\testimator lgbm's best error=0.6257,\tbest estimator lgbm's best error=0.6257\n",
            "[flaml.automl: 10-01 12:31:14] {1748} INFO - iteration 2, current learner lgbm\n",
            "[flaml.automl: 10-01 12:31:14] {1944} INFO -  at 0.1s,\testimator lgbm's best error=0.3498,\tbest estimator lgbm's best error=0.3498\n",
            "[flaml.automl: 10-01 12:31:14] {1748} INFO - iteration 3, current learner xgboost\n",
            "[flaml.automl: 10-01 12:31:14] {1944} INFO -  at 0.1s,\testimator xgboost's best error=3.1963,\tbest estimator lgbm's best error=0.3498\n",
            "[flaml.automl: 10-01 12:31:14] {1748} INFO - iteration 4, current learner lgbm\n",
            "[flaml.automl: 10-01 12:31:14] {1944} INFO -  at 0.2s,\testimator lgbm's best error=0.2466,\tbest estimator lgbm's best error=0.2466\n",
            "[flaml.automl: 10-01 12:31:14] {1748} INFO - iteration 5, current learner lgbm\n",
            "[flaml.automl: 10-01 12:31:14] {1944} INFO -  at 0.2s,\testimator lgbm's best error=0.2466,\tbest estimator lgbm's best error=0.2466\n",
            "[flaml.automl: 10-01 12:31:14] {1748} INFO - iteration 6, current learner lgbm\n",
            "[flaml.automl: 10-01 12:31:14] {1944} INFO -  at 0.2s,\testimator lgbm's best error=0.2087,\tbest estimator lgbm's best error=0.2087\n",
            "[flaml.automl: 10-01 12:31:14] {1748} INFO - iteration 7, current learner lgbm\n",
            "[flaml.automl: 10-01 12:31:14] {1944} INFO -  at 0.3s,\testimator lgbm's best error=0.2087,\tbest estimator lgbm's best error=0.2087\n",
            "[flaml.automl: 10-01 12:31:14] {1748} INFO - iteration 8, current learner lgbm\n",
            "[flaml.automl: 10-01 12:31:14] {1944} INFO -  at 0.3s,\testimator lgbm's best error=0.2087,\tbest estimator lgbm's best error=0.2087\n",
            "[flaml.automl: 10-01 12:31:14] {1748} INFO - iteration 9, current learner lgbm\n",
            "[flaml.automl: 10-01 12:31:14] {1944} INFO -  at 0.4s,\testimator lgbm's best error=0.1682,\tbest estimator lgbm's best error=0.1682\n",
            "[flaml.automl: 10-01 12:31:14] {1748} INFO - iteration 10, current learner xgboost\n",
            "[flaml.automl: 10-01 12:31:14] {1944} INFO -  at 0.4s,\testimator xgboost's best error=3.1963,\tbest estimator lgbm's best error=0.1682\n",
            "[flaml.automl: 10-01 12:31:14] {1748} INFO - iteration 11, current learner extra_tree\n",
            "[flaml.automl: 10-01 12:31:15] {1944} INFO -  at 1.5s,\testimator extra_tree's best error=0.3471,\tbest estimator lgbm's best error=0.1682\n",
            "[flaml.automl: 10-01 12:31:15] {1748} INFO - iteration 12, current learner rf\n",
            "[flaml.automl: 10-01 12:31:16] {1944} INFO -  at 2.7s,\testimator rf's best error=0.2872,\tbest estimator lgbm's best error=0.1682\n",
            "[flaml.automl: 10-01 12:31:16] {1748} INFO - iteration 13, current learner xgboost\n",
            "[flaml.automl: 10-01 12:31:16] {1944} INFO -  at 2.7s,\testimator xgboost's best error=0.8624,\tbest estimator lgbm's best error=0.1682\n",
            "[flaml.automl: 10-01 12:31:16] {1748} INFO - iteration 14, current learner xgboost\n",
            "[flaml.automl: 10-01 12:31:16] {1944} INFO -  at 2.8s,\testimator xgboost's best error=0.3204,\tbest estimator lgbm's best error=0.1682\n",
            "[flaml.automl: 10-01 12:31:16] {1748} INFO - iteration 15, current learner xgboost\n",
            "[flaml.automl: 10-01 12:31:16] {1944} INFO -  at 2.8s,\testimator xgboost's best error=0.3204,\tbest estimator lgbm's best error=0.1682\n",
            "[flaml.automl: 10-01 12:31:16] {1748} INFO - iteration 16, current learner lgbm\n",
            "[flaml.automl: 10-01 12:31:16] {1944} INFO -  at 2.8s,\testimator lgbm's best error=0.1682,\tbest estimator lgbm's best error=0.1682\n",
            "[flaml.automl: 10-01 12:31:16] {1748} INFO - iteration 17, current learner xgboost\n",
            "[flaml.automl: 10-01 12:31:16] {1944} INFO -  at 2.9s,\testimator xgboost's best error=0.2500,\tbest estimator lgbm's best error=0.1682\n",
            "[flaml.automl: 10-01 12:31:16] {1748} INFO - iteration 18, current learner lgbm\n",
            "[flaml.automl: 10-01 12:31:16] {1944} INFO -  at 3.0s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-01 12:31:16] {1748} INFO - iteration 19, current learner xgboost\n",
            "[flaml.automl: 10-01 12:31:16] {1944} INFO -  at 3.0s,\testimator xgboost's best error=0.2500,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-01 12:31:16] {1748} INFO - iteration 20, current learner lgbm\n",
            "[flaml.automl: 10-01 12:31:17] {1944} INFO -  at 3.1s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-01 12:31:17] {1748} INFO - iteration 21, current learner lgbm\n",
            "[flaml.automl: 10-01 12:31:17] {1944} INFO -  at 3.1s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-01 12:31:17] {1748} INFO - iteration 22, current learner lgbm\n",
            "[flaml.automl: 10-01 12:31:17] {1944} INFO -  at 3.2s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-01 12:31:17] {1748} INFO - iteration 23, current learner lgbm\n",
            "[flaml.automl: 10-01 12:31:17] {1944} INFO -  at 3.3s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-01 12:31:17] {1748} INFO - iteration 24, current learner xgboost\n",
            "[flaml.automl: 10-01 12:31:17] {1944} INFO -  at 3.3s,\testimator xgboost's best error=0.2500,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-01 12:31:17] {1748} INFO - iteration 25, current learner extra_tree\n",
            "[flaml.automl: 10-01 12:31:18] {1944} INFO -  at 4.5s,\testimator extra_tree's best error=0.2252,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-01 12:31:18] {1748} INFO - iteration 26, current learner lgbm\n",
            "[flaml.automl: 10-01 12:31:18] {1944} INFO -  at 4.6s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-01 12:31:18] {1748} INFO - iteration 27, current learner xgboost\n",
            "[flaml.automl: 10-01 12:31:18] {1944} INFO -  at 4.6s,\testimator xgboost's best error=0.2500,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-01 12:31:18] {1748} INFO - iteration 28, current learner xgboost\n",
            "[flaml.automl: 10-01 12:31:18] {1944} INFO -  at 4.6s,\testimator xgboost's best error=0.2500,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-01 12:31:18] {1748} INFO - iteration 29, current learner extra_tree\n",
            "[flaml.automl: 10-01 12:31:19] {1944} INFO -  at 5.8s,\testimator extra_tree's best error=0.2252,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-01 12:31:19] {1748} INFO - iteration 30, current learner lgbm\n",
            "[flaml.automl: 10-01 12:31:19] {1944} INFO -  at 5.9s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-01 12:31:19] {1748} INFO - iteration 31, current learner catboost\n",
            "[flaml.automl: 10-01 12:31:20] {1944} INFO -  at 6.8s,\testimator catboost's best error=0.1523,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-01 12:31:20] {1748} INFO - iteration 32, current learner lgbm\n",
            "[flaml.automl: 10-01 12:31:20] {1944} INFO -  at 6.9s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-01 12:31:20] {1748} INFO - iteration 33, current learner lgbm\n",
            "[flaml.automl: 10-01 12:31:20] {1944} INFO -  at 7.0s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-01 12:31:20] {1748} INFO - iteration 34, current learner xgboost\n",
            "[flaml.automl: 10-01 12:31:21] {1944} INFO -  at 7.0s,\testimator xgboost's best error=0.2500,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-01 12:31:21] {1748} INFO - iteration 35, current learner lgbm\n",
            "[flaml.automl: 10-01 12:31:21] {1944} INFO -  at 7.1s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-01 12:31:21] {1748} INFO - iteration 36, current learner rf\n",
            "[flaml.automl: 10-01 12:31:22] {1944} INFO -  at 8.2s,\testimator rf's best error=0.2209,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-01 12:31:22] {1748} INFO - iteration 37, current learner extra_tree\n",
            "[flaml.automl: 10-01 12:31:23] {1944} INFO -  at 9.4s,\testimator extra_tree's best error=0.2252,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-01 12:31:23] {1748} INFO - iteration 38, current learner xgboost\n",
            "[flaml.automl: 10-01 12:31:23] {1944} INFO -  at 9.4s,\testimator xgboost's best error=0.2500,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-01 12:31:23] {1748} INFO - iteration 39, current learner xgboost\n",
            "[flaml.automl: 10-01 12:31:23] {1944} INFO -  at 9.4s,\testimator xgboost's best error=0.2492,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-01 12:31:23] {1748} INFO - iteration 40, current learner lgbm\n",
            "[flaml.automl: 10-01 12:31:23] {1944} INFO -  at 9.5s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-01 12:31:23] {1748} INFO - iteration 41, current learner lgbm\n",
            "[flaml.automl: 10-01 12:31:23] {1944} INFO -  at 9.6s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-01 12:31:23] {1748} INFO - iteration 42, current learner lgbm\n",
            "[flaml.automl: 10-01 12:31:23] {1944} INFO -  at 9.6s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-01 12:31:23] {1748} INFO - iteration 43, current learner lgbm\n",
            "[flaml.automl: 10-01 12:31:23] {1944} INFO -  at 9.7s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-01 12:31:23] {1748} INFO - iteration 44, current learner lgbm\n",
            "[flaml.automl: 10-01 12:31:23] {1944} INFO -  at 9.7s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-01 12:31:23] {1748} INFO - iteration 45, current learner xgboost\n",
            "[flaml.automl: 10-01 12:31:23] {1944} INFO -  at 9.8s,\testimator xgboost's best error=0.2492,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-01 12:31:23] {1748} INFO - iteration 46, current learner lgbm\n",
            "[flaml.automl: 10-01 12:31:23] {1944} INFO -  at 9.9s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-01 12:31:23] {1748} INFO - iteration 47, current learner lgbm\n",
            "[flaml.automl: 10-01 12:31:23] {1944} INFO -  at 9.9s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-01 12:31:23] {1748} INFO - iteration 48, current learner xgboost\n",
            "[flaml.automl: 10-01 12:31:23] {1944} INFO -  at 10.0s,\testimator xgboost's best error=0.2492,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-01 12:31:23] {1748} INFO - iteration 49, current learner xgboost\n",
            "[flaml.automl: 10-01 12:31:23] {1944} INFO -  at 10.0s,\testimator xgboost's best error=0.2492,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-01 12:31:23] {2043} INFO - selected model: LGBMRegressor(colsample_bytree=0.6649148062238498,\n",
            "              learning_rate=0.17402065726724145, max_bin=128,\n",
            "              min_child_samples=3, n_estimators=32, num_leaves=9,\n",
            "              objective='regression', reg_alpha=0.0009765625,\n",
            "              reg_lambda=0.006761362450996487, verbose=-1)\n",
            "[flaml.automl: 10-01 12:31:24] {2106} INFO - retrain lgbm for 0.0s\n",
            "[flaml.automl: 10-01 12:31:24] {2110} INFO - retrained model: LGBMRegressor(colsample_bytree=0.6649148062238498,\n",
            "              learning_rate=0.17402065726724145, max_bin=128,\n",
            "              min_child_samples=3, n_estimators=32, num_leaves=9,\n",
            "              objective='regression', reg_alpha=0.0009765625,\n",
            "              reg_lambda=0.006761362450996487, verbose=-1)\n",
            "[flaml.automl: 10-01 12:31:24] {1539} INFO - fit succeeded\n",
            "[flaml.automl: 10-01 12:31:24] {1541} INFO - Time taken to find the best model: 2.950632095336914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[25.85426879 22.17737651 33.79509964 33.47189557 35.61127167 26.6926382\n",
            " 21.53656446 20.99173684 16.18673463 18.75433976 18.20961633 20.48286627\n",
            " 20.20745331 19.5131759  18.82401423 19.81864373 21.91420674 17.53721008\n",
            " 18.69698259 19.07769813 14.3021372  18.32367106 16.63348583 15.34809335\n",
            " 16.27978499 15.13176242 16.94561436 15.20221211 18.67737191 20.75076542\n",
            " 13.88486622 17.70376242 13.89318927 14.90744983 14.32837615 21.02020963\n",
            " 20.89410764 21.52937191 23.19568492 30.3824402  34.45306735 29.43834549\n",
            " 24.62262048 24.62262048 22.21884844 20.87353145 20.36481607 18.09945043\n",
            " 15.55273032 18.67322033 20.4058421  21.53510487 24.1301244  21.73345138\n",
            " 17.74586736 34.48285914 23.17178682 31.55632404 23.26235097 20.39233374\n",
            " 18.98627393 17.89811291 22.71262836 25.23349363 32.76974079 25.04432847\n",
            " 19.83367435 20.94710592 19.92700235 21.23614492 23.62275307 21.08771163\n",
            " 22.31713619 23.46816704 24.39319272 22.93449232 21.05889974 21.25605159\n",
            " 21.17094097 21.4104049  26.32531539 24.84165632 23.41875466 22.8120377\n",
            " 23.12681643 26.07314549 21.34032521 22.59488629 26.81601064 30.10072674\n",
            " 23.47133879 22.62450376 23.40848205 25.20150116 20.74313622 26.63582822\n",
            " 22.56394496 40.98684448 43.03722064 33.01766391 24.84190574 25.43455857\n",
            " 18.18875737 20.49979008 20.57478854 18.13734457 17.91303198 20.49979008\n",
            " 20.57478854 18.8322359  21.11833105 22.96406162 18.57150096 18.83508569\n",
            " 20.89066811 18.58619509 20.95795201 20.4381487  18.58619509 20.72664127\n",
            " 21.62721157 21.09344795 19.51757484 17.53599996 19.51757484 19.78584094\n",
            " 17.36958717 16.39253423 16.86856532 15.853506   19.71749942 19.35197602\n",
            " 20.07005987 17.39965131 15.92640822 17.14455857 16.51379168 18.47224498\n",
            " 14.38445978 16.3202417  14.36742357 13.09473563 14.46737843 14.73422787\n",
            " 13.79400434 15.41208419 17.4578433  13.90794056 14.77126156 15.18245573\n",
            " 20.57464694 19.22984984 18.55647575 18.00616692 18.32648919 16.20917324\n",
            " 15.94048355 40.44304575 24.93995665 24.55706495 26.17126032 47.56299085\n",
            " 48.57509584 48.92296041 21.89045992 23.47663172 48.88830552 21.21745586\n",
            " 22.24469801 22.12855254 21.21745586 21.21745586 20.71319839 23.99651065\n",
            " 22.20628325 27.61661251 22.24779919 24.35641132 28.82910017 37.4336891\n",
            " 41.82612485 31.40530134 37.2617559  31.63960058 24.06803666 27.95722996\n",
            " 48.31846952 28.85327104 30.14916251 34.44402572 32.43461899 29.21282212\n",
            " 34.58982726 29.81477151 29.09606486 48.42621104 33.91839935 30.81677594\n",
            " 32.76161643 33.0058017  33.0058017  23.35364085 43.33574902 48.15111119\n",
            " 48.42621104 23.7319089  23.12852809 20.08360727 22.292716   18.3152002\n",
            " 20.15144641 18.32878493 21.24073814 25.61968555 20.32169665 23.99488849\n",
            " 22.29871705 25.40375278 20.33285354 23.37310689 27.79745637 20.83190671\n",
            " 26.36215877 26.63632325 45.15579507 45.69665731 43.92509937 30.92171422\n",
            " 45.71273114 31.55492563 22.4680608  32.11251767 44.32137075 45.54983148\n",
            " 27.42782572 22.9617272  25.92533441 32.46382356 23.75605744 25.56397894\n",
            " 24.60210386 20.62465265 21.53758885 25.22345796 19.06214513 17.84017293\n",
            " 21.69626278 20.93442255 22.86047593 26.53529504 23.71037189 26.40330856\n",
            " 32.45002858 40.12441971 21.62770163 20.16906432 43.22019612 48.96580343\n",
            " 36.19046627 31.35388466 34.9431359  44.12722649 46.8156711  32.19902229\n",
            " 34.9431359  22.86211519 29.53873565 47.98290935 46.00178483 21.93765745\n",
            " 21.54793337 25.23142491 24.33883673 35.61319402 31.31696508 32.04267127\n",
            " 33.35308931 31.2559175  25.95200717 34.35510039 46.48696004 35.2163881\n",
            " 45.64080794 49.0327787  30.55331866 22.33257136 21.69757503 23.53652066\n",
            " 23.08245711 24.79937913 31.21276685 34.29118996 28.11258611 23.85939846\n",
            " 21.98861298 27.07522156 25.03558428 19.24341933 24.20354062 30.25026064\n",
            " 26.3510736  24.97967893 24.33108926 32.31816475 34.95139768 27.72254529\n",
            " 34.27356754 28.58064288 26.28401898 20.25949225 19.15765455 23.40595016\n",
            " 19.9069318  22.22895448 23.43789368 19.7967241  17.99129269 18.86799165\n",
            " 21.90295702 21.44864267 23.74221793 23.74221793 21.77357441 19.88044313\n",
            " 23.74861493 26.188891   24.33547333 21.31173366 20.3949194  23.03935223\n",
            " 22.0186464  19.24261422 19.64398129 21.95831249 21.85754325 20.6350395\n",
            " 20.01568444 19.85894712 20.79851822 20.16200017 20.51536951 31.99762077\n",
            " 20.68060523 25.59062004 30.87902463 19.41753345 18.59475908 23.18796837\n",
            " 25.72871802 28.3234078  22.31812575 24.88336613 21.31087817 31.0527335\n",
            " 19.34403778 20.75173519 15.87445808 20.5265433  20.70117246 20.5265433\n",
            " 23.32606114 19.68233643 20.00496907 17.88381107 28.83843559 24.00526687\n",
            " 19.09817287 21.32938439 50.07163944 48.82160629 48.20203737 47.2777543\n",
            " 46.84319485 14.36205747 13.53142624 17.48924424 11.79294408 12.03751809\n",
            " 10.7690999  11.77270178 13.30284038 10.53147486 11.61391857 11.4278251\n",
            "  9.02188405  8.92022632  9.50462006  8.55668465  9.66190862 11.96240478\n",
            " 14.65412353 17.1613234  10.55147356 14.45336107 12.65116497 14.27056086\n",
            " 13.89813053 11.94012717  7.77595912  9.18480867  8.37379402 10.28701903\n",
            " 11.98974767  9.49769797  7.70573926  7.36799143 13.36327035 26.14624567\n",
            " 15.17003545 20.94325541 16.51890218 16.88756044 14.57744105 14.89023868\n",
            "  8.24976464  8.63264333  9.50804859  8.93571718  7.75831071  9.03788871\n",
            " 15.02396264 15.06486095 19.58003642 12.86473687 13.39712744  8.56134775\n",
            " 13.56904967 10.98178079 10.67788405 10.28130892 14.4042725  15.46887706\n",
            " 17.90238886 15.34185827 12.90173312 11.40186526 10.99905848  9.72482922\n",
            "  9.45412739 11.70236191  9.99097952 13.44394369 16.75333771 14.22574262\n",
            " 10.75976886 10.18568291 16.33703165 14.63372832 15.14455645 15.09377379\n",
            " 14.00999287 16.72939436 17.1613234  16.21455097 12.35874932 14.39549294\n",
            " 14.28247556 12.85554461 15.09377379 18.58227987 16.47031642 18.94780328\n",
            " 19.79664167 20.4529397  21.22275643 20.45709742 15.75204166 16.60776586\n",
            " 17.55418796 19.39206231 18.10615643 20.45030404 20.66821931 28.06922267\n",
            " 16.67357885 16.26120202 17.72975505 13.19839222 17.20168726 20.15508873\n",
            " 20.90931887 24.17717967 27.62733557 20.78673312 20.75924242 21.3133487\n",
            " 18.99382477 20.93387158 15.10676681 11.06340755 10.26917289 15.17721649\n",
            " 17.95736363 21.10085132 21.34700608 21.00568378 17.69219141 20.52223098\n",
            " 20.76838574 18.76022157 20.23462213 22.18273078 19.05073131 26.01075867\n",
            " 22.94032743 16.83667178]\n",
            "<flaml.model.LGBMEstimator object at 0x7f0a9df5c610>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThYM5e7TxriP"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5eRkuWMxUcr",
        "outputId": "73e65552-94a9-4cf8-aaea-125a77d5eba0"
      },
      "source": [
        "# Predict\n",
        "print(automl.predict(X_train))\n",
        "# Export the best model\n",
        "print(automl.model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[25.85426879 22.17737651 33.79509964 33.47189557 35.61127167 26.6926382\n",
            " 21.53656446 20.99173684 16.18673463 18.75433976 18.20961633 20.48286627\n",
            " 20.20745331 19.5131759  18.82401423 19.81864373 21.91420674 17.53721008\n",
            " 18.69698259 19.07769813 14.3021372  18.32367106 16.63348583 15.34809335\n",
            " 16.27978499 15.13176242 16.94561436 15.20221211 18.67737191 20.75076542\n",
            " 13.88486622 17.70376242 13.89318927 14.90744983 14.32837615 21.02020963\n",
            " 20.89410764 21.52937191 23.19568492 30.3824402  34.45306735 29.43834549\n",
            " 24.62262048 24.62262048 22.21884844 20.87353145 20.36481607 18.09945043\n",
            " 15.55273032 18.67322033 20.4058421  21.53510487 24.1301244  21.73345138\n",
            " 17.74586736 34.48285914 23.17178682 31.55632404 23.26235097 20.39233374\n",
            " 18.98627393 17.89811291 22.71262836 25.23349363 32.76974079 25.04432847\n",
            " 19.83367435 20.94710592 19.92700235 21.23614492 23.62275307 21.08771163\n",
            " 22.31713619 23.46816704 24.39319272 22.93449232 21.05889974 21.25605159\n",
            " 21.17094097 21.4104049  26.32531539 24.84165632 23.41875466 22.8120377\n",
            " 23.12681643 26.07314549 21.34032521 22.59488629 26.81601064 30.10072674\n",
            " 23.47133879 22.62450376 23.40848205 25.20150116 20.74313622 26.63582822\n",
            " 22.56394496 40.98684448 43.03722064 33.01766391 24.84190574 25.43455857\n",
            " 18.18875737 20.49979008 20.57478854 18.13734457 17.91303198 20.49979008\n",
            " 20.57478854 18.8322359  21.11833105 22.96406162 18.57150096 18.83508569\n",
            " 20.89066811 18.58619509 20.95795201 20.4381487  18.58619509 20.72664127\n",
            " 21.62721157 21.09344795 19.51757484 17.53599996 19.51757484 19.78584094\n",
            " 17.36958717 16.39253423 16.86856532 15.853506   19.71749942 19.35197602\n",
            " 20.07005987 17.39965131 15.92640822 17.14455857 16.51379168 18.47224498\n",
            " 14.38445978 16.3202417  14.36742357 13.09473563 14.46737843 14.73422787\n",
            " 13.79400434 15.41208419 17.4578433  13.90794056 14.77126156 15.18245573\n",
            " 20.57464694 19.22984984 18.55647575 18.00616692 18.32648919 16.20917324\n",
            " 15.94048355 40.44304575 24.93995665 24.55706495 26.17126032 47.56299085\n",
            " 48.57509584 48.92296041 21.89045992 23.47663172 48.88830552 21.21745586\n",
            " 22.24469801 22.12855254 21.21745586 21.21745586 20.71319839 23.99651065\n",
            " 22.20628325 27.61661251 22.24779919 24.35641132 28.82910017 37.4336891\n",
            " 41.82612485 31.40530134 37.2617559  31.63960058 24.06803666 27.95722996\n",
            " 48.31846952 28.85327104 30.14916251 34.44402572 32.43461899 29.21282212\n",
            " 34.58982726 29.81477151 29.09606486 48.42621104 33.91839935 30.81677594\n",
            " 32.76161643 33.0058017  33.0058017  23.35364085 43.33574902 48.15111119\n",
            " 48.42621104 23.7319089  23.12852809 20.08360727 22.292716   18.3152002\n",
            " 20.15144641 18.32878493 21.24073814 25.61968555 20.32169665 23.99488849\n",
            " 22.29871705 25.40375278 20.33285354 23.37310689 27.79745637 20.83190671\n",
            " 26.36215877 26.63632325 45.15579507 45.69665731 43.92509937 30.92171422\n",
            " 45.71273114 31.55492563 22.4680608  32.11251767 44.32137075 45.54983148\n",
            " 27.42782572 22.9617272  25.92533441 32.46382356 23.75605744 25.56397894\n",
            " 24.60210386 20.62465265 21.53758885 25.22345796 19.06214513 17.84017293\n",
            " 21.69626278 20.93442255 22.86047593 26.53529504 23.71037189 26.40330856\n",
            " 32.45002858 40.12441971 21.62770163 20.16906432 43.22019612 48.96580343\n",
            " 36.19046627 31.35388466 34.9431359  44.12722649 46.8156711  32.19902229\n",
            " 34.9431359  22.86211519 29.53873565 47.98290935 46.00178483 21.93765745\n",
            " 21.54793337 25.23142491 24.33883673 35.61319402 31.31696508 32.04267127\n",
            " 33.35308931 31.2559175  25.95200717 34.35510039 46.48696004 35.2163881\n",
            " 45.64080794 49.0327787  30.55331866 22.33257136 21.69757503 23.53652066\n",
            " 23.08245711 24.79937913 31.21276685 34.29118996 28.11258611 23.85939846\n",
            " 21.98861298 27.07522156 25.03558428 19.24341933 24.20354062 30.25026064\n",
            " 26.3510736  24.97967893 24.33108926 32.31816475 34.95139768 27.72254529\n",
            " 34.27356754 28.58064288 26.28401898 20.25949225 19.15765455 23.40595016\n",
            " 19.9069318  22.22895448 23.43789368 19.7967241  17.99129269 18.86799165\n",
            " 21.90295702 21.44864267 23.74221793 23.74221793 21.77357441 19.88044313\n",
            " 23.74861493 26.188891   24.33547333 21.31173366 20.3949194  23.03935223\n",
            " 22.0186464  19.24261422 19.64398129 21.95831249 21.85754325 20.6350395\n",
            " 20.01568444 19.85894712 20.79851822 20.16200017 20.51536951 31.99762077\n",
            " 20.68060523 25.59062004 30.87902463 19.41753345 18.59475908 23.18796837\n",
            " 25.72871802 28.3234078  22.31812575 24.88336613 21.31087817 31.0527335\n",
            " 19.34403778 20.75173519 15.87445808 20.5265433  20.70117246 20.5265433\n",
            " 23.32606114 19.68233643 20.00496907 17.88381107 28.83843559 24.00526687\n",
            " 19.09817287 21.32938439 50.07163944 48.82160629 48.20203737 47.2777543\n",
            " 46.84319485 14.36205747 13.53142624 17.48924424 11.79294408 12.03751809\n",
            " 10.7690999  11.77270178 13.30284038 10.53147486 11.61391857 11.4278251\n",
            "  9.02188405  8.92022632  9.50462006  8.55668465  9.66190862 11.96240478\n",
            " 14.65412353 17.1613234  10.55147356 14.45336107 12.65116497 14.27056086\n",
            " 13.89813053 11.94012717  7.77595912  9.18480867  8.37379402 10.28701903\n",
            " 11.98974767  9.49769797  7.70573926  7.36799143 13.36327035 26.14624567\n",
            " 15.17003545 20.94325541 16.51890218 16.88756044 14.57744105 14.89023868\n",
            "  8.24976464  8.63264333  9.50804859  8.93571718  7.75831071  9.03788871\n",
            " 15.02396264 15.06486095 19.58003642 12.86473687 13.39712744  8.56134775\n",
            " 13.56904967 10.98178079 10.67788405 10.28130892 14.4042725  15.46887706\n",
            " 17.90238886 15.34185827 12.90173312 11.40186526 10.99905848  9.72482922\n",
            "  9.45412739 11.70236191  9.99097952 13.44394369 16.75333771 14.22574262\n",
            " 10.75976886 10.18568291 16.33703165 14.63372832 15.14455645 15.09377379\n",
            " 14.00999287 16.72939436 17.1613234  16.21455097 12.35874932 14.39549294\n",
            " 14.28247556 12.85554461 15.09377379 18.58227987 16.47031642 18.94780328\n",
            " 19.79664167 20.4529397  21.22275643 20.45709742 15.75204166 16.60776586\n",
            " 17.55418796 19.39206231 18.10615643 20.45030404 20.66821931 28.06922267\n",
            " 16.67357885 16.26120202 17.72975505 13.19839222 17.20168726 20.15508873\n",
            " 20.90931887 24.17717967 27.62733557 20.78673312 20.75924242 21.3133487\n",
            " 18.99382477 20.93387158 15.10676681 11.06340755 10.26917289 15.17721649\n",
            " 17.95736363 21.10085132 21.34700608 21.00568378 17.69219141 20.52223098\n",
            " 20.76838574 18.76022157 20.23462213 22.18273078 19.05073131 26.01075867\n",
            " 22.94032743 16.83667178]\n",
            "<flaml.model.LGBMEstimator object at 0x7f0a9df5c610>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7kvrow81vYL"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}